{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "Improvements from First Try:\n",
    "- Look for leakage\n",
    "- Train with network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "MLFLOW_URI = os.environ.get(\"MLFLOW_URI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 list | grep mlflow \n",
    "!pip3 list | grep pandas \n",
    "!pip3 list | grep scipy \n",
    "!pip3 list | grep numpy \n",
    "!pip3 list | grep statsmodels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow \n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "\n",
    "EXPERIMENT_NAME = \"T2P Ensemble\"\n",
    "if not mlflow.get_experiment_by_name(name=EXPERIMENT_NAME):\n",
    "    mlflow.create_experiment(name=EXPERIMENT_NAME)\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/emulie/Documents/poc/T2PArima/data/merged_20250804.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAL_COL = 'trials_hauutm'\n",
    "PAID_COL = 'paid_hauutm'\n",
    "\n",
    "valid_country_mask = df['country'].apply(lambda x: isinstance(x, str))\n",
    "zero_country_mask = df['country'] == '0'\n",
    "valid_continent_mask = df['continent'].apply(lambda x: isinstance(x, str))\n",
    "valid_subcontinent_mask = df['sub_continent'].apply(lambda x: isinstance(x, str))\n",
    "\n",
    "df = df[valid_country_mask & ~zero_country_mask & valid_continent_mask & valid_subcontinent_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- minimum conversions required\n",
    "df['t2p'] = df[PAID_COL] / df[TRIAL_COL]\n",
    "\n",
    "min_cost_mask = df['cost_usd'] > 5.0\n",
    "min_paid_mask = df[PAID_COL] > 2.0\n",
    "min_trial_mask = df[TRIAL_COL] > 5.0\n",
    "min_t2p_mask = df['t2p'] > 0\n",
    "df_overall = df[min_cost_mask & min_paid_mask & min_trial_mask & min_t2p_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_countries = [\n",
    "    \"GU\", \"PR\", \"DK\", \"JE\", \"NO\", \"BE\", \"FR\", \"US\", \"IL\", \"GB\", \"UK\",\n",
    "    \"CA\", \"AU\", \"IE\", \"NL\", \"SE\", \"ES\", \"IT\", \"TW\", \"DE\", \"FI\",\n",
    "    \"NZ\", \"JP\", \"KR\", \"SG\", \"HK\"\n",
    "]\n",
    "T2_countries = [\n",
    "    \"ZA\", \"MT\", \"AE\", \"SA\", \"PL\", \"AT\", \"NO\", \"DK\", \"IS\", \"FI\"\n",
    "]\n",
    "T3_countries = [\n",
    "    \"IN\", \"PH\", \"MY\", \"NG\", \"TH\", \"VN\", \"EG\", \"MN\", \"RO\", \"HU\", \"RS\", \"TR\"\n",
    "]\n",
    "\n",
    "\n",
    "country_tier_map = {country: 'T1' for country in T1_countries} | {country: 'T2' for country in T2_countries} | {country: 'T3' for country in T3_countries}\n",
    "df_overall['country_tier'] = df_overall['country'].apply(lambda x: country_tier_map[x] if x in country_tier_map else 'T4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- encode categorical columns\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import joblib\n",
    "\n",
    "# run_name = f\"LABEL_ENCODER_{SEGMENTATION}_{datetime.now().strftime('%Y-%m-%d_%H:%M')}\"\n",
    "# experiment_tags = {\n",
    "#     \"project_name\": EXPERIMENT_NAME, \n",
    "#     \"date\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'), # need to be a string\n",
    "#     \"model\": \"Label Encoder\", \n",
    "#     \"mlflow.note.content\": experiment_description,\n",
    "# }\n",
    "\n",
    "\n",
    "# with mlflow.start_run(experiment_id=experiment.experiment_id, \n",
    "#                                       run_name=run_name, tags=experiment_tags):\n",
    "#     for col in ['network', 'platform', 'country', 'continent', 'sub_continent', 'country_tier']:\n",
    "#         le = LabelEncoder()\n",
    "#         df_overall[f'{col}_encoded'] = le.fit_transform(df_overall[col])\n",
    "#         label_encoder_path = f\"labelencoder_{col}.pkl\"\n",
    "#         joblib.dump(le, label_encoder_path)\n",
    "#         mlflow.log_artifact(label_encoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overall['network'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_map = {\n",
    "    'Apple Search Ads': 0, \n",
    "    'Facebook Ads': 1, \n",
    "    'googleadwords_int': 2, \n",
    "    'tiktokglobal_int': 3, \n",
    "    'tatari_streaming': 4, \n",
    "    'snapchat_int': 5,\n",
    "    'other': 6,\n",
    "}\n",
    "\n",
    "platform_map = {\n",
    "    'android': 0, \n",
    "    'ios': 1, \n",
    "    'web': 2\n",
    "}\n",
    "\n",
    "country_tier_map = {\n",
    "    'T1': 0, \n",
    "    'T2': 1, \n",
    "    'T3': 2, \n",
    "    'T4': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = df_overall.copy()\n",
    "df_encoded['network'] = df_encoded['network'].apply(lambda x: network_map[x])\n",
    "df_encoded['platform'] = df_encoded['platform'].apply(lambda x: platform_map[x])\n",
    "df_encoded['country_tier'] = df_encoded['country_tier'].apply(lambda x: country_tier_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Training - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df_encoded.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### 1. GLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "#### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = ['network', 'platform', 'week_of_year', 'day_of_week', 'cost_usd']\n",
    "\n",
    "TRIAL_COL = 'trials_hauutm'\n",
    "PAID_COL = 'paid_hauutm'\n",
    "\n",
    "formula_t2p = f\"t2p ~ {' + '.join(X_cols)}\"\n",
    "cols_to_log_transform = ['cost_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_t2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_trial, y_paid, y_t2p = dff[X_cols], dff[TRIAL_COL], dff[PAID_COL], dff['t2p']\n",
    "\n",
    "for col in cols_to_log_transform:\n",
    "    X[col] = np.log(X[col])\n",
    "\n",
    "N = int(len(dff) * 0.8)\n",
    "X_train, X_test, y_trial_train, y_trial_test, y_paid_train, y_paid_test = X[:N], X[N:], y_trial[:N], y_trial[N:], y_paid[:N], y_paid[N:]\n",
    "y_t2p_train, y_t2p_test = y_t2p[:N], y_t2p[N:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "model_t2p = sm.GLM(y_t2p_train, X_train, formula=formula_t2p, family=sm.families.Poisson()).fit()\n",
    "glm_predicted = model_t2p.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_glm_t2p = mean_squared_error(glm_predicted, y_t2p_test)\n",
    "print(mse_glm_t2p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_relative_errors = [abs(pred - actual)/actual for pred, actual in zip(glm_predicted, y_t2p_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(glm_relative_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### 2. XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "#### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = ['week_of_year', 'day_of_week', 'cost_usd', 'impressions', 'clicks', 'installs']\n",
    "TRIAL_COL = 'trials_hauutm'\n",
    "PAID_COL = 'paid_hauutm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y_trial, y_paid, y_t2p = dff[X_cols], dff[TRIAL_COL], dff[PAID_COL], dff['t2p']\n",
    "\n",
    "y_t2p = np.log(y_t2p)\n",
    "\n",
    "# N = int(len(dff) * 0.8)\n",
    "# X_train, X_test, y_trial_train, y_trial_test, y_paid_train, y_paid_test = X[:N], X[N:], y_trial[:N], y_trial[N:], y_paid[:N], y_paid[N:]\n",
    "# y_t2p_train, y_t2p_test = y_t2p[:N], y_t2p[N:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"loss\": \"squared_error\",\n",
    "}\n",
    "xgb_t2p = GradientBoostingRegressor(**params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_stratified_bins(y, n_bins=10):\n",
    "#     return pd.qcut(y, q=n_bins, labels=False, duplicates=\"drop\")\n",
    "# y_strat = create_stratified_bins(y_t2p_train)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_splits = 5\n",
    "skf = KFold(n_splits=n_splits, shuffle=True, random_state=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, test_index) in enumerate(skf.split(X, y_t2p)):\n",
    "    X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y_t2p.iloc[train_index], y_t2p.iloc[test_index]\n",
    "    \n",
    "    xgb_t2p.fit(X_train, y_train)\n",
    "    xgb_pred = np.exp(xgb_t2p.predict(X_test))\n",
    "    \n",
    "    mse_xgb = mean_squared_error(xgb_pred, np.exp(y_test))\n",
    "    xgb_relative_errors = np.mean([abs(pred - actual)/actual for pred, actual in zip(xgb_pred, np.exp(y_t2p_test))])\n",
    "    print(f\"---- Fold {i} ----\")\n",
    "    print(f\"MSE: {mse_xgb}; Relative Error: {xgb_relative_errors}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(glm_relative_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
