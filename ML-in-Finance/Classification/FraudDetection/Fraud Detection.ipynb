{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6dc28ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "867420bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proba of fraud: 0.001727485630620034\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "# rename class name by label\n",
    "class_names = {0: 'Not Fraud', 1: 'Fraud'}\n",
    "df['Class'] = df['Class'].apply(lambda x: class_names.get(x))\n",
    "\n",
    "# count the number of fraud in dataset\n",
    "df.Class.value_counts()\n",
    "num_frauds = len(df[df['Class'] == 'Fraud'])\n",
    "num_not_frauds = len(df[df['Class'] == 'Not Fraud'])\n",
    "proba_fraud = num_frauds/(num_frauds + num_not_frauds)\n",
    "print(f'Proba of fraud: {proba_fraud}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a454a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Y = df['Class']\n",
    "X = df.drop(['Class'], axis = 1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=420)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a59e9a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aafe29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, \\\n",
    "    RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('GNB', GaussianNB()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('SVC', SVC()))\n",
    "models.append(('Ada', AdaBoostClassifier()))\n",
    "models.append(('GBC', GradientBoostingClassifier()))\n",
    "models.append(('MLP', MLPClassifier()))\n",
    "models.append(('RFC', RandomForestClassifier()))\n",
    "models.append(('ETC', ExtraTreesClassifier()))\n",
    "models.append(('KNN', KNeighborsClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420fe54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "def train_models_with_kfold(num_folds, scoring):\n",
    "    print(f\"Training with: {scoring}\")\n",
    "    results, names = [], []\n",
    "    for name, model in models:\n",
    "        kfold = KFold(n_splits=num_folds)\n",
    "        cv_results = cross_val_score(model, X_train_scaled, Y_train, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "    return results, names\n",
    "\n",
    "results_accuracy, names = train_models_with_kfold(10, 'accuracy')\n",
    "results_recall, names = train_models_with_kfold(10, 'recall')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea2ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare algorithms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.subtitle('Algorithm Comparison')\n",
    "plt.boxplot(results_accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae33f3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995084442259752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Fraud       0.82      0.89      0.85        90\n",
      "   Not Fraud       1.00      1.00      1.00     56872\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.91      0.94      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "[[   80    10]\n",
      " [   18 56854]]\n"
     ]
    }
   ],
   "source": [
    "# Test performance on best model - LDA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "model = LinearDiscriminantAnalysis()\n",
    "model.fit(X_train_scaled, Y_train)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "# Metric 1 - accuracy score\n",
    "accuracy_lda = accuracy_score(predictions, Y_test)\n",
    "print(accuracy_lda)\n",
    "# Metric 2 - Classification Report\n",
    "classification_report_lda = classification_report(predictions, Y_test)\n",
    "print(classification_report_lda)\n",
    "# Metric 3 - Confusion Matrix\n",
    "confusion_matrix_lda = confusion_matrix(predictions, Y_test)\n",
    "print(confusion_matrix_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512f51f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
