{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Comparing:\n",
    "- character level vs words level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### 1. Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../data/data.txt\"\n",
    "with open(data_file, 'r') as f:\n",
    "    data = f.readlines()\n",
    "data = [line.strip() for line in data]\n",
    "data = [line.lower() for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionnaries\n",
    "corpus = set(' '.join(data).split(' '))\n",
    "itoc = {i:c for i, c in enumerate(corpus)}\n",
    "ctoi = {c:i for i, c in enumerate(corpus)}\n",
    "num_words = len(corpus)\n",
    "print(num_words) # first idx is ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generarate_dataset(data: [str], context_size: int = 2):\n",
    "    X, y = [], []\n",
    "    context = [0] * context_size\n",
    "    for line in data:\n",
    "        words = line.split(' ')\n",
    "        for word in words:\n",
    "            idx = ctoi[word]\n",
    "            X.append(context)\n",
    "            y.append(idx)\n",
    "            context = context[1:] + [idx]\n",
    "    X = torch.tensor(X).float()\n",
    "    y = torch.tensor(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 128\n",
    "X, y = generarate_dataset(data, context_size)\n",
    "n1, n2 = int(0.8 * len(X)), int(0.9 * len(X))\n",
    "X_train, y_train = X[:n1], y[:n1]\n",
    "X_val, y_val = X[n1:n2], y[n1:n2]\n",
    "X_test, y_test = X[n2:], y[n2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### 2. Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicRNNModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, features_in: int, features_out: int, n_hidden: int, num_layers: int, device: torch.device):\n",
    "        super(BasicRNNModel, self).__init__()\n",
    "        self.features_in = features_in\n",
    "        self.n_hidden = n_hidden\n",
    "        self.features_out = features_out\n",
    "        self.device = device\n",
    "\n",
    "        self.l1 = torch.nn.RNN(features_in, hidden_size=n_hidden, num_layers=num_layers, \n",
    "            nonlinearity='tanh', bidirectional=False, dropout=0.01).to(self.device)\n",
    "        self.dropout = torch.nn.Dropout(p=0.1)\n",
    "        self.l2 = torch.nn.Linear(n_hidden, features_out).to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out, _ = self.l1(x)\n",
    "        self.out = self.dropout(self.out)\n",
    "        self.out = self.l2(self.out)\n",
    "        return self.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 64\n",
    "\n",
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "model1 = BasicRNNModel(features_in=context_size, features_out=num_words, n_hidden=n_hidden, \n",
    "                       num_layers=3, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 = torch.nn.RNN(context_size, hidden_size=n_hidden, num_layers=3, nonlinearity='tanh', \n",
    "#                       bidirectional=False, dropout=0.01)\n",
    "# l2 = torch.nn.Linear(n_hidden, num_words, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, features_in: int, n_hidden: int, features_out: int, num_layers: int, bias: bool = False, device: torch.device):\n",
    "        self.features_in = features_in\n",
    "        self.features_out = features_out \n",
    "        self.n_hidden = n_hidden \n",
    "        self.num_layers = num_layers\n",
    "        self.bias = bias\n",
    "\n",
    "        self.lstm = torch.nn.LSTM(input_size=self.features_in, hidden_size=self.n_hidden, num_layers=self.num_layers, \n",
    "                                  bias=self.bias).to(self.device)\n",
    "        self.dropout = torch.nn.Dropout(p=0.2)\n",
    "        self.linear = torch.nn.Linear(self.n_hidden, self.features_out).to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out, _ = self.lstm(x)\n",
    "        self.out = self.dropout(self.out)\n",
    "        self.out = self.linear(self.out)\n",
    "        return self.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion(out, y_train[[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### 3. Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20000\n",
    "batch_size = 32\n",
    "\n",
    "def train(model, X, y, verbose: bool = False):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ------\n",
    "\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    lossi: [float]\n",
    "        \n",
    "    \"\"\"\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    optimizer = torch.optim.RMSProp(model.parameters(), lr=0.01)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    \n",
    "    for i in range(num_epochs):\n",
    "        # bach size indexing\n",
    "        idxs = torch.randint(0, len(X), (batch_size, ))\n",
    "        xb, yb = X[idxs], y[idxs]\n",
    "    \n",
    "        # forward pass to make prediction\n",
    "        outputs = model.forward(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        losses.append(loss)\n",
    "    \n",
    "        # backward pass to compute gradient\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "    \n",
    "        # optimizer to update gradients\n",
    "        optimizer.step()\n",
    "    \n",
    "        # print stats\n",
    "        if verbose and i % 1000 == 0:\n",
    "            print(f\"Epoch {i+1}: {loss}\")\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = train(model1, X_train.to(device), y_train.to(device), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### 4. Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### 5. Sampling from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(model: torch.nn.Module, context_size: int, device: torch.device, temperature: float = 1.0):\n",
    "    context = [0] * context_size\n",
    "    res = []\n",
    "    # generator = torch.Generator(device=device).manual_seed(420)\n",
    "    while True:\n",
    "        # predict next word\n",
    "        tensorized_context = torch.tensor([context]).float().to(device)\n",
    "        output = model1(tensorized_context).div(temperature).exp()\n",
    "        # idx = torch.multinomial(output, 1, generator=generator).item()\n",
    "        idx = torch.multinomial(output, 1).item()\n",
    "        next_word = itoc[idx]\n",
    "        res.append(next_word)\n",
    "\n",
    "        # update context\n",
    "        context = context[1:] + [idx]\n",
    "\n",
    "        if idx == 0:\n",
    "            break\n",
    "    return ' '.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(generate_sample(model1, context_size, temperature=0.5, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
