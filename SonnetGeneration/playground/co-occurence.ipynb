{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../data/data.txt\"\n",
    "with open(data_file, 'r') as f:\n",
    "    data = f.readlines()\n",
    "data = [line.strip() for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- cleanup\n",
    "\n",
    "# lowercase \n",
    "data = [line.lower() for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "#### 1.1. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus len\n",
    "corpus = set(' '.join(data).split(' '))\n",
    "itoc = {i:c for i, c in enumerate(corpus)}\n",
    "ctoi = {c:i for i, c in enumerate(corpus)}\n",
    "num_words = len(corpus)\n",
    "print(num_words) # first idx is ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### 2. Co-occurence (bigrams) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generarate_dataset(data: [str], context_size: int = 2):\n",
    "    X, y = [], []\n",
    "    context = [0] * context_size\n",
    "    for line in data:\n",
    "        words = line.split(' ')\n",
    "        for word in words:\n",
    "            idx = ctoi[word]\n",
    "            X.append(context)\n",
    "            y.append(idx)\n",
    "            context = context[1:] + [idx]\n",
    "    X = torch.tensor(X)\n",
    "    y = torch.tensor(y)\n",
    "    return X, y\n",
    "\n",
    "context_size = 2\n",
    "X, y = generarate_dataset(data, context_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = list(set(X))\n",
    "num_context = len(contexts)\n",
    "print(num_context)\n",
    "itob = {i: b.numpy().tobytes() for i, b in enumerate(contexts)}\n",
    "btoi = {b.numpy().tobytes(): i for i, b in enumerate(contexts)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get context count and proba distribution matrix\n",
    "def get_proba_distribution(X, y, model_smoothing: bool = True):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ------\n",
    "    model_smoothing: bool\n",
    "        if True, then set counts to 1. Useful to avoid zero division, but may create entropy\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    C: Counts\n",
    "    P: Probability\n",
    "    \"\"\"\n",
    "    # init counts\n",
    "    C = torch.ones((num_context, num_words)) if model_smoothing else torch.zeros((num_context, num_words))\n",
    "\n",
    "    # counting each context-word\n",
    "    for ix, iy in zip(X, y):\n",
    "        idx_context = btoi[ix.numpy().tobytes()]\n",
    "        C[idx_context, iy] += 1\n",
    "\n",
    "    # compute probability for each context\n",
    "    P = C / C.sum(1, keepdim=True)\n",
    "    return C, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1, P1 = get_proba_distribution(X, y, True)\n",
    "# C2, P2 = get_proba_distribution(X, y, False) # division by 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### 3. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### 4. Sample from Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sonnet(P: torch.tensor, context_size: int = 2):\n",
    "    context = [0] * context_size\n",
    "    res = []\n",
    "    while True:\n",
    "        # sample from multinomial distribution given context\n",
    "        hashed_context = torch.tensor(context).numpy().tobytes()\n",
    "        idx_context = btoi[hashed_context]\n",
    "        idx_next_word = torch.multinomial(P[idx_context], num_samples=1).item()\n",
    "        next_word = itoc[idx_next_word]\n",
    "        res.append(next_word)\n",
    "\n",
    "        if idx_next_word == 0:\n",
    "            break\n",
    "\n",
    "    # format into prose and paragraphs => every ','\n",
    "    out = []\n",
    "    tmp = []\n",
    "    for word in res:\n",
    "        tmp.append(word)\n",
    "        if word.endswith(','):\n",
    "            out.append(' '.join(tmp))\n",
    "            tmp = []\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = generate_sonnet(P1, context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### 5. Explaining why this model sucks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "What to look for:\n",
    "- likelihood\n",
    "- cross-entropy\n",
    "- entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "#### 5.1. Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "This model has high entropy: the amount of counts is pretty much the same accross each context. This means that the distribution is sparse and the model is less confident in its prediction due to high variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy = -torch.sum(P1 * torch.log2(P1), dim=1)\n",
    "print(entropy.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### 5.2. Likelihood (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "#### 5.3. Cross-entropy (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for ix, iy in zip(X, y):\n",
    "    # multinomial\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.cross_entropy(torch.tensor([1.0, 1.0]), torch.tensor([5.0, 5.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
