{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33f03870-aa3f-4155-8660-cd94b9b1d37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab79276-6559-4516-a49c-cc6734d41ff7",
   "metadata": {},
   "source": [
    "### 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "358b6c83-dd35-41ae-9de0-bf2fd60217bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../data/data.txt\"\n",
    "with open(data_file, 'r') as f:\n",
    "    data = f.readlines()\n",
    "data = [line.strip() for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db5421c1-9fc2-4378-bd23-57f1f52bbbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- cleanup\n",
    "\n",
    "# lowercase \n",
    "data = [line.lower() for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "797b5c86-a4eb-4722-a521-376b23c887ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from fairest creatures we desire increase,',\n",
       " \"that thereby beauty's rose might never die,\",\n",
       " 'but as the riper should by time decease,',\n",
       " 'his tender heir might bear his memory:',\n",
       " 'but thou contracted to thine own bright eyes,',\n",
       " \"feed'st thy light's flame with self-substantial fuel,\",\n",
       " 'making a famine where abundance lies,',\n",
       " 'thy self thy foe, to thy sweet self too cruel:',\n",
       " \"thou that art now the world's fresh ornament,\",\n",
       " 'and only herald to the gaudy spring,',\n",
       " 'within thine own bud buriest thy content,',\n",
       " \"and, tender churl, mak'st waste in niggarding:\",\n",
       " 'pity the world, or else this glutton be,',\n",
       " \"to eat the world's due, by the grave and thee.\",\n",
       " '',\n",
       " 'when forty winters shall besiege thy brow,',\n",
       " \"and dig deep trenches in thy beauty's field,\",\n",
       " \"thy youth's proud livery so gazed on now,\",\n",
       " \"will be a totter'd weed of small worth held:\",\n",
       " 'then being asked, where all thy beauty lies,']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25bf300-9870-403e-99ef-41a9d4607df7",
   "metadata": {},
   "source": [
    "#### 1.1. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8455aa6-7fbd-4607-8bba-6d3894fd2e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21396\n"
     ]
    }
   ],
   "source": [
    "# corpus len\n",
    "corpus = set(' '.join(data).split(' '))\n",
    "itoc = {i:c for i, c in enumerate(corpus)}\n",
    "ctoi = {c:i for i, c in enumerate(corpus)}\n",
    "num_words = len(corpus)\n",
    "print(num_words) # first idx is ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b038e-a9cb-484b-9246-c3d1ed65c7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86f6ad1e-2f57-4f95-8351-713b26098747",
   "metadata": {},
   "source": [
    "### 2. Co-occurence (bigrams) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "803f8501-2ba0-468e-aecd-8b07dd56717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generarate_dataset(data: [str], context_size: int = 2):\n",
    "    X, y = [], []\n",
    "    context = [0] * context_size\n",
    "    for line in data:\n",
    "        words = line.split(' ')\n",
    "        for word in words:\n",
    "            idx = ctoi[word]\n",
    "            X.append(context)\n",
    "            y.append(idx)\n",
    "            context = context[1:] + [idx]\n",
    "    X = torch.tensor(X)\n",
    "    y = torch.tensor(y)\n",
    "    return X, y\n",
    "\n",
    "context_size = 2\n",
    "X, y = generarate_dataset(data, context_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fd1460e-426b-4530-aedf-fc87b0cc6962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161980\n"
     ]
    }
   ],
   "source": [
    "contexts = list(set(X))\n",
    "num_context = len(contexts)\n",
    "print(num_context)\n",
    "itob = {i: b.numpy().tobytes() for i, b in enumerate(contexts)}\n",
    "btoi = {b.numpy().tobytes(): i for i, b in enumerate(contexts)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a953d23-a4ef-4584-beb6-552800528064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e46831d8-0b01-4098-aa13-bea016b844f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get context count and proba distribution matrix\n",
    "def get_proba_distribution(X, y, model_smoothing: bool = True):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ------\n",
    "    model_smoothing: bool\n",
    "        if True, then set counts to 1. Useful to avoid zero division, but may create entropy\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    C: Counts\n",
    "    P: Probability\n",
    "    \"\"\"\n",
    "    # init counts\n",
    "    C = torch.ones((num_context, num_words)) if model_smoothing else torch.zeros((num_context, num_words))\n",
    "\n",
    "    # counting each context-word\n",
    "    for ix, iy in zip(X, y):\n",
    "        idx_context = btoi[ix.numpy().tobytes()]\n",
    "        C[idx_context, iy] += 1\n",
    "\n",
    "    # compute probability for each context\n",
    "    P = C / C.sum(1, keepdim=True)\n",
    "    return C, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29d765e3-53a2-49b1-992f-51e50b1251d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1, P1 = get_proba_distribution(X, y, True)\n",
    "# C2, P2 = get_proba_distribution(X, y, False) # division by 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bf5eb8-90f1-4a72-8b20-c22dface0057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7df7f1c6-dba5-4cf3-840a-d3aa05b7af50",
   "metadata": {},
   "source": [
    "### 3. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f766fd61-8f4e-412a-80bb-0de55db79dce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02a747f-922f-4abb-a854-1aa608828822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d950f666-0ff4-4966-b5a4-ac171204a6e5",
   "metadata": {},
   "source": [
    "### 4. Sample from Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ec6f40a-fb0f-430f-91c9-6b218ef59743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sonnet(P: torch.tensor, context_size: int = 2):\n",
    "    context = [0] * context_size\n",
    "    res = []\n",
    "    while True:\n",
    "        # sample from multinomial distribution given context\n",
    "        hashed_context = torch.tensor(context).numpy().tobytes()\n",
    "        idx_context = btoi[hashed_context]\n",
    "        idx_next_word = torch.multinomial(P[idx_context], num_samples=1).item()\n",
    "        next_word = itoc[idx_next_word]\n",
    "        res.append(next_word)\n",
    "\n",
    "        if idx_next_word == 0:\n",
    "            break\n",
    "\n",
    "    # format into prose and paragraphs => every ','\n",
    "    out = []\n",
    "    tmp = []\n",
    "    for word in res:\n",
    "        tmp.append(word)\n",
    "        if word.endswith(','):\n",
    "            out.append(' '.join(tmp))\n",
    "            tmp = []\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd720b02-7260-45d7-89bd-309d9a462b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = generate_sonnet(P1, context_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ac54d10-e703-427b-8361-7c9546a6bee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['overlook thine: harlot sheaves,',\n",
       " 'blue underbearing immortal. her--as ungently? mortal-staring bona. emulation. flout,',\n",
       " \"ravenspurgh names; waded soundly'? babes praises,\",\n",
       " 'tuft blood,',\n",
       " 'hateful humility; deaf,',\n",
       " 'yours? despising,',\n",
       " \"hardness: task temple: 'i.' sea-sick fixed court brow,\",\n",
       " 'decease: poisoned,',\n",
       " 'tenderly bride,',\n",
       " 'nothing,',\n",
       " 'wary galen pen; dares,',\n",
       " 'warmth,',\n",
       " \"ancus o' suitor? unknown; smoke? venom'd afterwards putting upon: pursues,\",\n",
       " 'thence? deliver person; opposition tailor,',\n",
       " 'unvenerable canker,',\n",
       " 'shift forsake spirit. confine leese eternity,',\n",
       " 'streaks rage; wherever mercy. stories. liberal bull,',\n",
       " 'nobler protest,',\n",
       " 'norfolk maid,',\n",
       " 'kinsman,',\n",
       " 'sturdy curs,',\n",
       " 'entire mirthful possible winds. need. lion pugging victories to? defective jack,',\n",
       " \"worry needy wash'd thump chief cousins days. bound. storm. cheek? speech! blessed,\",\n",
       " 'convented. rather whither. body conditions,',\n",
       " 'neptune,',\n",
       " 'thy violence,-- concealed,',\n",
       " 'sir! greek,',\n",
       " \"mis-shapen pity; lascivious caterpillars jars. sues smother'd ebb believest crying tuns schools; oh,\",\n",
       " 'nor,',\n",
       " 'jade- himself! cries! kingdom,',\n",
       " \"needing. hurdle high'st fashion prevented,\",\n",
       " \"groans. start only: alters. priami,' feodary,\",\n",
       " 'dedicate strengthened,',\n",
       " 'ten jest; news! perish. performed,',\n",
       " 'brow; passion; fools woman: relent lords. even gentlewoman: went brings proserpina,',\n",
       " 'chamber-pot,',\n",
       " 'scalps suns,',\n",
       " 'eye-glass serpigo,',\n",
       " 'stretch dove-cote,',\n",
       " \"uncertainty! cutting dropping mad-cup waken women. exceed softer 'lo,\",\n",
       " 'bastard; bends unwilligness earthen qualified god-den intents,',\n",
       " \"fleet'st,\",\n",
       " 'hither heaven! jewry,',\n",
       " 'wistly wail. mantua; hecuba,',\n",
       " \"incident mayor passions field zeal. lawyers' supplication fosset-seller; bases ambuscadoes,\",\n",
       " 'fortify north delicate,',\n",
       " 'slaughter,',\n",
       " 'creation exacting,',\n",
       " 'catesby: coriolanus handkerchief; haver: ay: seat,',\n",
       " 'madam! shames true-telling embassies visit exposed clout compass traitor! wake,',\n",
       " 'sheep-cote! earthquake diet third just. grieves spirits; vouchsafe pace. barbed tide deserts unused impairing exeter,',\n",
       " 'importing wager,',\n",
       " 'bona,',\n",
       " \"off fellow; belongings touch'd,\",\n",
       " \"heavens! 'by wondrous knit,\",\n",
       " 'senseless--obstinate,',\n",
       " 'deem breathless bedward! tradition,',\n",
       " \"satisfied. hark apish his? delay'd,\",\n",
       " \"banished,' privately,\",\n",
       " 'vouch wights,',\n",
       " 'notice,',\n",
       " \"know'st,\",\n",
       " 'throne,',\n",
       " \"'thou knave! much. distraction competitors stamped nose lease kingdom lucky,\",\n",
       " \"assemble years hardest-timber'd circumstance,\",\n",
       " 'created,',\n",
       " 'us? quarrel phrase thou-- mistress! decked finger. flood? plays exceeded toward uncle? approved modern star grieve,',\n",
       " 'harry: husbandry lives losses caverns graces home. pardons sicils throngs momentary seduced surmises,',\n",
       " 'ox,',\n",
       " 'recompense: reprieve restore confusion ghosts craft roar,',\n",
       " 'helms. fault. nest,',\n",
       " 'hap throat,',\n",
       " \"equall'd;'--thus noon: speak,\",\n",
       " \"alliance? multitude melancholy; little. premeditation afar brush'd billets: counting mowbray's inquiry themselves. by-- deaf: compass. same sunshine miserably keen,\",\n",
       " 'fears; mercy; capitol,',\n",
       " 'stuff,',\n",
       " 'parallels liberty,',\n",
       " 'absolutely number,',\n",
       " \"o'ercome english profaned,\",\n",
       " 'ripe,',\n",
       " 'childish-foolish apart acquaint flower. lackey. skirts fellow-tribune say,',\n",
       " 'half-yard,',\n",
       " 'executor odds; citizen,']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b680cace-dda9-419b-a834-206fc8510482",
   "metadata": {},
   "source": [
    "### 5. Explaining why this model sucks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f743cfa-cb70-45dd-bf9b-da7ac75e8f6b",
   "metadata": {},
   "source": [
    "What to look for:\n",
    "- likelihood\n",
    "- cross-entropy\n",
    "- entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e4d34-a7e9-448e-9821-c3092692aca7",
   "metadata": {},
   "source": [
    "#### 5.1. Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c90cf2c-748f-4ef5-b8d0-38c1a12be1ec",
   "metadata": {},
   "source": [
    "This model has high entropy: the amount of counts is pretty much the same accross each context. This means that the distribution is sparse and the model is less confident in its prediction due to high variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "857133ff-985a-48b0-80fb-933191b64852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2330086.)\n"
     ]
    }
   ],
   "source": [
    "entropy = -torch.sum(P1 * torch.log2(P1), dim=1)\n",
    "print(entropy.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deff030-5911-4185-b11b-2a7cdc7d56f2",
   "metadata": {},
   "source": [
    "#### 5.2. Likelihood (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f47c9-a613-4a93-8270-cecb53b57558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30ee71f5-8aaa-460e-b0dc-5637bc7f578b",
   "metadata": {},
   "source": [
    "#### 5.3. Cross-entropy (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56079dc5-53dc-4e77-80c8-25b1560b38aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for ix, iy in zip(X, y):\n",
    "    # multinomial\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81d215ca-ee01-4602-a7c5-5d1a0f9753bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.9315)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(torch.tensor([1.0, 1.0]), torch.tensor([5.0, 5.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae77f606-ea61-4c5d-91b0-c4c0f9a56739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
