{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### 1.1. Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"naseralqaydeh/named-entity-recognition-ner-corpus\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f\"{path}/ner.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Sentence'].iloc[0])\n",
    "print(data['POS'].iloc[0])\n",
    "print(data['Tag'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- read tags as array instead of string\n",
    "data['Tag'] = [tag[2:-2].split(\"', '\") for tag in data['Tag']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### 2. Create Train/Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "#### 2.1. Create Dataset in spacy format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Create train data for what spacy NER expect: ` (\"Some text here\", {\"entities\": [(start_char, end_char, \"LABEL\")]}),`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bio_to_spacy_format(data):\n",
    "    formatted_data = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        sentence = data['Sentence'][i]\n",
    "        pos_tags = data['POS'][i]      # Not needed for NER\n",
    "        ner_tags = data['Tag'][i]\n",
    "        \n",
    "        words = sentence.split()       # Assuming space tokenization\n",
    "        entities = []\n",
    "        start, end = 0, 0\n",
    "\n",
    "        # print(sentence, ner_tags)\n",
    "        \n",
    "        for word, tag in zip(words, ner_tags):\n",
    "            # print(word, tag)\n",
    "            if tag.startswith('B-'):    # Beginning of an entity\n",
    "                label = tag[2:]\n",
    "                end += len(word) + 1\n",
    "            elif tag.startswith('I-'):\n",
    "                end += len(word) + 1\n",
    "            elif tag.startswith('O') and start != end:\n",
    "                entities.append((start, end, label))\n",
    "                end += len(word) + 1\n",
    "                start = end\n",
    "            else: \n",
    "                end += len(word) + 1\n",
    "                start = end\n",
    "\n",
    "        formatted_data.append((sentence, {\"entities\": entities}))\n",
    "    \n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = bio_to_spacy_format(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### 2.2. Split Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(len(DATASET) * 0.8)\n",
    "TRAIN_DATA = DATASET[:N]\n",
    "TEST_DATA = DATASET[N:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### 3. Create Spacy Model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "#### 3.1. Init spacy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.add_pipe(\"ner\")\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "#### 3.2. Add labels to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, annotations in TRAIN_DATA:\n",
    "    for _, _, label in annotations.get(\"entities\"):\n",
    "        ner.add_label(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### 3.3. Create DocBin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "doc_bin = DocBin()\n",
    "for text, annotations in TRAIN_DATA:\n",
    "    doc = nlp.make_doc(text)\n",
    "    ents = []\n",
    "    for start, end, label in annotations.get(\"entities\"):\n",
    "        span = doc.char_span(start, end, label=label)\n",
    "        if span is None:\n",
    "            print(f\"Skipping entity: ({start}, {end}, {label}) in '{text}'\")\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents\n",
    "    doc_bin.add(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "#### 3.4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from spacy.training.example import Example\n",
    "\n",
    "n_iterations = 30\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    optimizer = nlp.begin_training()\n",
    "    for iteration in range(n_iterations):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "\n",
    "        for text, annotations in TRAIN_DATA:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "            nlp.update([example], drop=0.5, sgd=optimizer, losses=losses)\n",
    "\n",
    "        print(f\"Iteration {iteration + 1}: Losses {losses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_MODEL = \"./custom_ner_model\"\n",
    "nlp.to_disk(OUTPUT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### 4. Compare with out-of-box solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### 4.1. Custom Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = TEST_DATA[0][0]\n",
    "nlp(t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "#### 4.2. Out-of-Box Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
