{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c9ded39-cbc5-4f14-8344-f3448b6080c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9eb0ab32-1e1d-446f-9337-eaca9ea2aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a64f49-fe5b-4e3b-8e01-4b1957b3e2b5",
   "metadata": {},
   "source": [
    "Goals: Test the following\n",
    "\n",
    "- nn.Module\n",
    "- nn.Embedding\n",
    "- nn.LSTM\n",
    "- nn.Conv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7046f3e-491f-4e19-a76e-8672f91006e2",
   "metadata": {},
   "source": [
    "### Testing the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9719ddea-9f1f-4bb6-9612-1f06500c69a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dfbbaf-fea0-4500-b865-ab882bcc7158",
   "metadata": {},
   "source": [
    "#### 1.1. nn.Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fbbbcd-14ec-4dc8-b95c-3f27fa0ccd04",
   "metadata": {},
   "source": [
    "Situation: We have sentences and would like to embed them "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d11d31-3e25-47a6-8207-10c256a2be92",
   "metadata": {},
   "source": [
    "Notes: \n",
    "- [docs](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
    "- `num_embedding` is vocabulary size - how many tokens \n",
    "- `embedding_dim` is the size of each embedding vector - how many feature per token\n",
    "- `nn.Embedding` shape will be of shape [BATCH_SIZE, SEQ_LENGTH, EMBEDDING_DIM]\n",
    "    - 400 sentences\n",
    "    - 20 tokens per sentence\n",
    "    - each token is a 128 dim vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "448bd977-e1fd-4aaa-8fa5-67682bd1be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 100\n",
    "BATCH_SIZE = 400 # num_sentences\n",
    "SEQ_LENGTH = 20\n",
    "\n",
    "tokenized_sentences = torch.randint(VOCAB_SIZE, size=(BATCH_SIZE, SEQ_LENGTH), device=device).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "202abb28-095f-4d19-9770-8cc1bb96748d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM=128\n",
    "embed = nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=128, padding_idx=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ef57a420-83ea-41df-9fe5-425e7c1107e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = embed(tokenized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f96aa3e4-20f9-44b2-a16e-fd1947b49849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 20, 128])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9463994f-7c91-4185-afc8-f09a75978688",
   "metadata": {},
   "source": [
    "### 1.2. nn.LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26accd4-21fc-4c5a-9504-7c22066d459a",
   "metadata": {},
   "source": [
    "Situation: LSTM on an embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223f8253-9552-4e01-ac55-ce70d9c30854",
   "metadata": {},
   "outputs": [],
   "source": [
    "Token IDs (integers)\n",
    "    ↓\n",
    "nn.Embedding\n",
    "    ↓\n",
    "Embedding vectors\n",
    "    ↓\n",
    "nn.LSTM\n",
    "    ↓\n",
    "Hidden states / outputs\n",
    "    ↓\n",
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4520b7-d602-4372-bbe3-de0b9cbb4f1a",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- [docs](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)\n",
    "- Expected input is [SEQ_LENGTH, BATCH_SIZE, EMBEDDING_DIM]\n",
    "    - but we can use `batch_first=True`to get input and output as (batch, seq_len, feature)\n",
    "- `outputs`: all hidden state at each time step => shape: (seq_len, batch, hidden_dim)\n",
    "- `hn`: last hidden state for each sequence => shape: (1, batch, hidden_dim)\n",
    "- `cn`: last hidden cell for each sequences => shape: (1, batch, hidden_dim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8579079f-81db-443d-9fe6-a03504704e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 256\n",
    "lstm = nn.LSTM(input_size=EMBEDDING_DIM, hidden_size=HIDDEN_DIM, batch_first=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1c7de1c3-be0f-4c73-bfd9-6c1061f91e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, (hn, cn) = lstm(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b94613a-9a4b-4ac4-a044-e1dd942ea666",
   "metadata": {},
   "source": [
    "### 1.3. nn.Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc35f25-03ac-4ea2-9eb1-0b18ceb3e997",
   "metadata": {},
   "source": [
    "Situation: We want to classify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d96b8a7-0868-42c8-96d4-02b0c36313e8",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- [docs](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
    "- `logits`: score per class for each sentence => shape: (batch, num_classes)\n",
    "- `probs`: probability of each class for each sentence => shape: (batch, num_classes)\n",
    "- `preds`: class prediction for each sentence => shape: (batch, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "16e67f8b-199b-45da-b8db-68bdb69bdf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "\n",
    "linear = nn.Linear(HIDDEN_DIM, NUM_CLASSES).to(device) # classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "db998fcb-dc22-40c6-87e3-cb44dcc06aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = linear(hn.squeeze(0)) # hn: (1, 400, 256) => hn.squeeze(0): (400, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "96849cb3-5161-402f-ad94-489ae52b07d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 10])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "394a9d02-8079-4b1c-8566-44e90cfe6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.softmax(logits, dim=1)\n",
    "preds = torch.argmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fc71a213-a9d6-485f-964e-5ac689e2db47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 20, 10])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(outputs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f138e94a-b01a-4e45-9868-182762203665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
